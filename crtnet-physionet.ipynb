{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Howto\n",
        "\n",
        "\n",
        "1. Decide if wanting to process the data and evaluate the same as CRT-Net paper, ie allow whatever label classes are in the data, but for each sample, just pick the first diagnosis OR do it PhysioNet competition style where only samples from a certain number of labels (as per csv file) are used but also each sample can have multiple labels\n",
        "1. If you want CRT-Net style, run the cell where data is loaded with load_data given the argument adjust_classes_for_physionet as false. This will produce three file, the data samples themselves, the one hot encoded labels (only one per sample) and the discovered class names, to make it easier later to translate on hot labels to readable class names\n",
        "1. If you want PhysioNet style, run cell with load_data given the argument adjust_classes_for_physionet as true\n",
        "1. Run the cell that creates the train/evaluate functions plus creates the baseline crt_net model\n",
        "1. Run other cells to create other models\n",
        "1. Change the cell to read whatever numpy datafiles you like, and train/evaluate. It will work out whether to do multilabel or single label based on the onehot encoding"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The below reads .hea and .mat file pairs and then :\n",
        "\n",
        "- Standardises the sample lengths to the most common length (unless overridden), and sampling frequency to the most common frequency.\n",
        "- One hot encodes the diagnostic class label, either picking the first \"primary\" label, or encoding all labels. The first case is consistency with the CRT-Net paper, the second for consistency with PhysioNet challenge\n",
        "- To also be consistent with the PhysioNet challenge, it is also catered to restrict the classes to a certain specified set (via csv file), and also to ensure the \"normal\" class is always present\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "snomed_to_abbreviation = {\n",
        "    '7':'164884008',\n",
        "    '2':'164889003',\n",
        "    '4':'164909002',\n",
        "    '9':'164931005',\n",
        "    '3':'270492004',\n",
        "    '6':'284470004',\n",
        "    '1':'426783006',\n",
        "    '8':'429622005',\n",
        "    '5':'59118001'\n",
        "}\n",
        "\n",
        "def read_records(record_files, csv_file_path=None):\n",
        "    records = []\n",
        "    labels = []\n",
        "\n",
        "    if (csv_file_path is not None):\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    for record_file in record_files:\n",
        "        record = wfdb.rdrecord(record_file)\n",
        "\n",
        "        if(csv_file_path is not None):\n",
        "            recording_id = record.file_name[0].split('.')[0]  # Assuming the recording ID is in the file name\n",
        "        \n",
        "            # Extract the First_label for the corresponding recording (numbner) and map it longer number\n",
        "            first_label_str = df[df['Recording'] == recording_id]['First_label'].astype(str).values[0]\n",
        "            first_label_mapped = snomed_to_abbreviation[first_label_str]\n",
        "            \n",
        "            labels.append(first_label_mapped)\n",
        "\n",
        "        for comment in record.comments:\n",
        "            if comment.startswith('Dx') or comment.startswith(' Dx'):\n",
        "                dxs = set(arr.strip() for arr in comment.split(': ')[1].split(','))\n",
        "                labels.append(dxs)\n",
        "                    \n",
        "        records.append(wfdb.rdrecord(record_file))\n",
        "    return records, labels\n",
        "\n",
        "\n",
        "def create_one_hot_labels(all_labels, target_classes, num_recordings, single_label):\n",
        "    discard_index = list()\n",
        "    labels = np.zeros((num_recordings, len(target_classes)))  # , dtype=np.bool)\n",
        "    for i in range(num_recordings):\n",
        "        dxs = all_labels[i]\n",
        "        flag = np.zeros((1, len(dxs)), dtype=bool)\n",
        "        count = 0\n",
        "        for dx in dxs:\n",
        "            if dx in target_classes:\n",
        "                j = target_classes.index(dx)\n",
        "                labels[i, j] = 1\n",
        "                flag[0, count] = True\n",
        "                \n",
        "                # Break out of the loop if adjust_classes_for_physionet is not set\n",
        "                if single_label:\n",
        "                    break\n",
        "\n",
        "            count += 1\n",
        "\n",
        "        # note any recordings that don't have any of the classes we are looking for\n",
        "        if np.any(flag) == False:\n",
        "            discard_index.append(i)\n",
        "\n",
        "    return labels, discard_index\n",
        "\n",
        "def get_unique_classes(all_labels, valid_classes=None):\n",
        "\n",
        "    classes2 = list()\n",
        "    for i in range(len(all_labels)):\n",
        "        dxs = all_labels[i]\n",
        "        for dx in dxs:\n",
        "            if valid_classes is None or dx in valid_classes:\n",
        "                classes2.append(dx)\n",
        "\n",
        "    classes3 = list()\n",
        "    for x in classes2:\n",
        "        if x not in classes3:\n",
        "            classes3.append(x)\n",
        "\n",
        "    classes3 = sorted (classes3)\n",
        "    return classes3\n",
        "\n",
        "def find_records(directory):\n",
        "    record_files = []\n",
        "    for dirpath, _, filenames in os.walk(directory):\n",
        "        for f in sorted(filenames):\n",
        "            file_path = os.path.join(dirpath, f)\n",
        "            if os.path.isfile(file_path) and not f.lower().startswith('.'):\n",
        "                file, ext = os.path.splitext(file_path)\n",
        "                if ext.lower() == '.hea':\n",
        "                    record_files.append(file)\n",
        "    if record_files:\n",
        "        return record_files\n",
        "    else:\n",
        "        raise IOError('No record files found.')\n",
        "\n",
        "def filter(data, labels, index):\n",
        "    labels = [labels[i] for i in range(len(labels)) if i not in index]\n",
        "    data = [data[i] for i in range(len(data)) if i not in index]\n",
        "    return labels, data\n",
        "\n",
        "def consolidate_equivalent_classes(one_hot_encoded_labels, unique_classes):\n",
        "    equivalent_classes_collection = [['713427006', '59118001'], ['284470004', '63593006'], ['427172004', '17338001']]\n",
        "\n",
        "    # For each set of equivalent class, use only one class as the representative class for the set and discard the other classes in the set.\n",
        "    # The label for the representative class is positive if any of the labels in the set is positive.\n",
        "    remove_classes = list()\n",
        "    remove_indices = list()\n",
        "    for equivalent_classes in equivalent_classes_collection:\n",
        "        equivalent_classes = [x for x in equivalent_classes if x in unique_classes]\n",
        "        if len(equivalent_classes)>1:\n",
        "            other_classes = equivalent_classes[1:]\n",
        "            equivalent_indices = [unique_classes.index(x) for x in equivalent_classes]\n",
        "            representative_index = equivalent_indices[0]\n",
        "            other_indices = equivalent_indices[1:]\n",
        "\n",
        "            one_hot_encoded_labels[:, representative_index] = np.any(one_hot_encoded_labels[:, equivalent_indices], axis=1)\n",
        "            remove_classes += other_classes\n",
        "            remove_indices += other_indices\n",
        "\n",
        "    for x in remove_classes:\n",
        "        unique_classes.remove(x)\n",
        "    one_hot_encoded_labels = np.delete(one_hot_encoded_labels, remove_indices, axis=1)\n",
        "\n",
        "    return one_hot_encoded_labels, unique_classes\n",
        "\n",
        "def set_labels_to_normal_if_none_other(labels, unique_classes, normal_class):\n",
        "    # If the labels are negative for all classes, then change the label for the normal class to positive.\n",
        "    normal_index = unique_classes.index(normal_class)\n",
        "    for i in range(len(labels)):\n",
        "        num_positive_classes = np.sum(labels[i, :])\n",
        "        if num_positive_classes==0:\n",
        "            labels[i, normal_index] = 1\n",
        "\n",
        "    return labels\n",
        "\n",
        "def ensure_normal_class(unique_classes, normal_class):\n",
        "    if normal_class not in unique_classes:\n",
        "        unique_classes.add(normal_class)\n",
        "        print('- The normal class {} is not one of the label classes, so it has been automatically added, but please check that you chose the correct normal class.'.format(normal_class))\n",
        "    unique_classes = sorted(unique_classes)\n",
        "    return unique_classes\n",
        "\n",
        "def read_scored_classes():\n",
        "    scored = list()\n",
        "    with open('dx_mapping_scored.csv', 'r') as f:\n",
        "        for l in f:\n",
        "            dxs = (l.split(','))\n",
        "            scored.append(dxs[1])\n",
        "    return (sorted(scored[1:]))\n",
        "\n",
        "def filter_out(one_hot_encoded_labels, records, discard_index):\n",
        "    one_hot_encoded_labels = [one_hot_encoded_labels[i] for i in range(len(one_hot_encoded_labels)) if i not in discard_index]\n",
        "    records = [records[i] for i in range(len(records)) if i not in discard_index]\n",
        "\n",
        "    return one_hot_encoded_labels, records\n",
        "\n",
        "def load_records(record_file_list, adjust_classes_for_physionet, single_label, csv_file, normal_class):\n",
        "        \n",
        "    if len(record_file_list) == 0:\n",
        "        raise ValueError('No record files found.')\n",
        "\n",
        "    num_recordings = len(record_file_list)\n",
        "\n",
        "    records, all_labels = read_records(record_file_list, csv_file)\n",
        "\n",
        "    scored = None\n",
        "    if adjust_classes_for_physionet:\n",
        "        scored = read_scored_classes()\n",
        "\n",
        "    unique_classes = get_unique_classes(all_labels, scored)\n",
        "\n",
        "    if (normal_class is not None):\n",
        "        unique_classes = ensure_normal_class(unique_classes, normal_class)\n",
        "    \n",
        "    one_hot_encoded_labels, discard_index = create_one_hot_labels(all_labels, unique_classes, num_recordings, single_label=single_label)\n",
        "\n",
        "    if (adjust_classes_for_physionet):\n",
        "        one_hot_encoded_labels, unique_classes = consolidate_equivalent_classes(one_hot_encoded_labels, unique_classes)\n",
        "    \n",
        "    if (normal_class is not None):\n",
        "        one_hot_encoded_labels = set_labels_to_normal_if_none_other(one_hot_encoded_labels, unique_classes, normal_class)\n",
        "    \n",
        "    one_hot_encoded_labels, records = filter_out(one_hot_encoded_labels, records, discard_index)\n",
        "\n",
        "    return one_hot_encoded_labels, records, unique_classes\n",
        "\n",
        "def standardise_length(data, target_length):\n",
        "    number_of_leads = data.shape[0]\n",
        "    \n",
        "    if len(data[0])<=target_length:\n",
        "        ext= np.zeros([number_of_leads,target_length])\n",
        "        for i in range(0,number_of_leads):\n",
        "            ext[i][0:len(data[i])]=data[i]\n",
        "        return ext.T  \n",
        "    else:\n",
        "        cut = np.zeros([number_of_leads,target_length])\n",
        "        for i in range(number_of_leads):\n",
        "            tocut = len(data[0])- target_length\n",
        "            cut[i] = data[i][tocut:]\n",
        "        return cut.T \n",
        "\n",
        "def resample(data, src_frq, trg_frq):\n",
        "\n",
        "    if src_frq == trg_frq:\n",
        "        return data\n",
        "\n",
        "    N_src = data.shape[0]\n",
        "    N_trg = int(N_src * trg_frq / src_frq)\n",
        "    \n",
        "    resampled = np.zeros((N_trg, data.shape[1]), dtype='float32')\n",
        "    for i in range(data.shape[1]):\n",
        "        resampled[:,i] = np.interp(np.linspace(0, N_src, N_trg), np.arange(N_src), data[:, i])\n",
        "        \n",
        "    return resampled\n",
        "\n",
        "def standardise_data_samples(records, fixed_sample_length=None):\n",
        "    standardised_data = list()\n",
        "\n",
        "    # find the most common fs\n",
        "    fss = [record.fs for record in records]\n",
        "\n",
        "    target_fs = max(set(fss), key=fss.count)\n",
        "\n",
        "    # find the most common sig_len\n",
        "    sig_lens = [record.sig_len for record in records]\n",
        "\n",
        "    if (fixed_sample_length is not None):\n",
        "        target_length = fixed_sample_length\n",
        "    else:\n",
        "        target_length = max(set(sig_lens), key=sig_lens.count)\n",
        "\n",
        "    for i in range(len(records)):\n",
        "        datum = records[i].p_signal.T\n",
        "        datum = resample(datum,records[i].fs, target_fs)\n",
        "        datum = standardise_length(datum, target_length)\n",
        "        standardised_data.append(datum)\n",
        "\n",
        "    return standardised_data\n",
        "\n",
        "def load_data(input_directory, adjust_classes_for_physionet=False, single_label=False, csv_file=None, normal_class=None, fixed_sample_length=None):\n",
        "    record_file_list = find_records(input_directory)\n",
        "    \n",
        "    one_hot_encoded_labels, records, classes = load_records(record_file_list, adjust_classes_for_physionet, single_label=single_label, csv_file=csv_file, normal_class=normal_class)\n",
        "    samples = standardise_data_samples(records, fixed_sample_length=fixed_sample_length)\n",
        "            \n",
        "    one_hot_encoded_labels = np.stack(one_hot_encoded_labels, axis =0)\n",
        "    samples = np.stack(samples, axis =0)\n",
        "\n",
        "    return one_hot_encoded_labels, samples, classes\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1715557429372
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below to get an numpy output of samples, single one hot encoded label and the class names for the China 2018 data as used by the CRT-Net paper."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = 'data'\n",
        "input_directory = 'cpsc_2018'\n",
        "    \n",
        "one_hot_encoding_labels, samples, classes = load_data(input_directory, adjust_classes_for_physionet=False, single_label=True, csv_file='REFERENCE.csv', fixed_sample_length=3000)\n",
        "\n",
        "# maps SNOMED CT codes to classes\n",
        "snomed_to_abbreviation = {\n",
        "    '164884008': 'PVC',\n",
        "    '164889003': 'AF',\n",
        "    '164909002': 'LBBB',\n",
        "    '164931005': 'STE',\n",
        "    '270492004': 'IAVB',\n",
        "    '284470004': 'PAC',\n",
        "    '426783006': 'N',\n",
        "    '429622005': 'STD',\n",
        "    '59118001': 'RBBB'\n",
        "}\n",
        "\n",
        "# map classes to abbreviations\n",
        "mapped_abbreviations = [snomed_to_abbreviation.get(code, None) for code in classes]\n",
        "\n",
        "# save the data to a file\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_singlelabel_samples.npy'), samples)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_singlelabel_one_hot_encoding_labels.npy'), one_hot_encoding_labels)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_singlelabel_classes.npy'), mapped_abbreviations)\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1715557853313
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = 'data'\n",
        "input_directory = 'cpsc_2018'\n",
        "    \n",
        "one_hot_encoding_labels, samples, classes = load_data(input_directory, adjust_classes_for_physionet=False, single_label=False)\n",
        "\n",
        "# maps SNOMED CT codes to classes\n",
        "snomed_to_abbreviation = {\n",
        "    '164884008': 'PVC',\n",
        "    '164889003': 'AF',\n",
        "    '164909002': 'LBBB',\n",
        "    '164931005': 'STE',\n",
        "    '270492004': 'IAVB',\n",
        "    '284470004': 'PAC',\n",
        "    '426783006': 'N',\n",
        "    '429622005': 'STD',\n",
        "    '59118001': 'RBBB'\n",
        "}\n",
        "\n",
        "# map classes to abbreviations\n",
        "mapped_abbreviations = [snomed_to_abbreviation.get(code, None) for code in classes]\n",
        "\n",
        "# save the data to a file\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_multilabel_samples.npy'), samples)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_multilabel_one_hot_encoding_labels.npy'), one_hot_encoding_labels)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_crtnet_multilabel_classes.npy'), mapped_abbreviations)\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715531239662
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run below to get an numpy output of samples, multilabel one hot encoded labels and the class names for any PhysioNet data. This data will be restricted to the PhysioNet challenge list of classes and will be guaranteed to include the \"normal\" class.\n",
        "\n",
        "The can be run on any set of sets of PhysioNet data, including China 2018, PTB-XL etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_directory = 'data'\n",
        "input_directory = 'cpsc_2018'\n",
        "    \n",
        "one_hot_encoding_labels, samples, classes = load_data(input_directory, adjust_classes_for_physionet=True, single_label=False, normal_class='426783006')\n",
        "# save the data to a file\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_physionet_samples.npy'), samples)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_physionet_one_hot_encoding_labels.npy'), one_hot_encoding_labels)\n",
        "np.save(os.path.join(output_directory, 'cpsc_2018_physionet_classes.npy'), classes)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715304125386
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create functions to \n",
        "a) Train and evaluate a model, be it multilabel or single label\n",
        "b) Create our best attempt at the matching architecture, regularisation and hyperparameters for CRT-Net"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import keras_nlp as nlp \n",
        "import tensorflow.keras as keras\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import argmax\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from importlib import reload\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from src import crtnet_models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "reload(crtnet_models)\n",
        "\n",
        "\n",
        "def train_and_evaluate_model(model, samples, one_hot_encoding_labels, classes, multilabel, callbacks=None, epochs=10, batch_size=64, style=None):\n",
        "    \n",
        "    train_x, validation_x, train_y, validation_y = train_test_split(samples, one_hot_encoding_labels, test_size=0.1, random_state=42)\n",
        "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(validation_x, validation_y), callbacks=callbacks)\n",
        "\n",
        "    pd.DataFrame(history.history).plot(\n",
        "        figsize=(8, 5), xlim=[0, epochs], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
        "        style=[\"r--\", \"r--.\", \"b-\", \"b-*\"] if style is None else style)\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.show()\n",
        "        \n",
        "    # Classification Report\n",
        "    if classes is None:\n",
        "        classes = [\"Class \" + str(i) for i in range(len(np.unique(validation_y)))]\n",
        "\n",
        "    y_pred = model.predict(validation_x)\n",
        "\n",
        "    if (multilabel):\n",
        "        # Binarize y_pred to one-hot encoding if it contains probabilities\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        # Calculate overall accuracy\n",
        "        overall_accuracy = accuracy_score(validation_y, y_pred)\n",
        "        print(f\"Overall Accuracy: {overall_accuracy:.2%}\")\n",
        "\n",
        "        # Generate classification report\n",
        "        report = classification_report(y_true=validation_y, y_pred=y_pred, labels=list(range(validation_y.shape[1])), target_names=classes, zero_division=0)\n",
        "        print(report)\n",
        "\n",
        "        # Accuracy per class\n",
        "        accuracies_per_class = []\n",
        "        for i in range(validation_y.shape[1]):\n",
        "            class_accuracy = accuracy_score(validation_y[:, i], y_pred[:, i])\n",
        "            accuracies_per_class.append(class_accuracy)\n",
        "            print(f\"Accuracy ({classes[i]}): {class_accuracy:.2%}\")\n",
        "\n",
        "    else:\n",
        "        validation_y = np.argmax(validation_y, axis=1)\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        report = classification_report(y_true=validation_y, y_pred=y_pred, labels=np.unique(validation_y), target_names=classes,zero_division=0)\n",
        "        print(report)\n",
        "\n",
        "        # output accuracy per class\n",
        "        print('Accuracy per class:')\n",
        "        for i in range(len(classes)):\n",
        "            print(f'{classes[i]}: {np.round(100*sum(validation_y[validation_y==i] == y_pred[validation_y==i])/sum(validation_y==i), 2)}%')\n",
        "\n",
        "        # Confusion Matrix\n",
        "        cm = confusion_matrix(validation_y, y_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Reds', xticklabels=classes, yticklabels=classes)\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "def create_crtnet_original(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_original(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "def create_crtnet_our_transformer(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_modular(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate,\n",
        "        alternate_arch=True,\n",
        "        att_type='our_transformer'\n",
        "    )\n",
        "\n",
        "def create_crtnet_dense(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_modular(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate,\n",
        "        alternate_arch=True,\n",
        "        extra_dense=True,\n",
        "        att_type='transformer'\n",
        "    )\n",
        "\n",
        "def create_crtnet_no_transformer(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_modular(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate,\n",
        "        alternate_arch=True,\n",
        "        att_type='none'\n",
        "    )\n",
        "\n",
        "def create_crtnet_dense_noselu(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_modular(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate,\n",
        "        alternate_arch=True,\n",
        "        extra_dense=True,\n",
        "        att_type='transformer',\n",
        "        use_selu=False\n",
        "    )\n",
        "\n",
        "def create_crtnet_alternate(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_original_alt(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "def create_crtnet_rwkv(number_of_leads=1, num_classes=5, multilabel=False, learning_rate=0.001):\n",
        "    tf.keras.backend.clear_session()\n",
        "    return crtnet_models.crt_net_modular(\n",
        "        n_classes=num_classes,\n",
        "        input_shape=(None,number_of_leads),\n",
        "        rkwv_stack_multiplier=4,\n",
        "        n_vgg_blocks=5, # increased signal length so more CNN blocks to downsample (3000 / 2**5 -> 94)\n",
        "        binary=multilabel, # set this to true if using multilabel output (disables softmax and categorical cross entropy). CPSC can be multilabel.\n",
        "        use_focal=True, # addresses significant class imbalance (enables focal cross entropy)\n",
        "        metrics=['accuracy'], # May be better to evaluate on F1 score if using early stopping\n",
        "        d_model=128, # default feature dim size (d_ffn set to 2*d_model)\n",
        "        att_type='rwkv',\n",
        "        alternate_arch=True,\n",
        "        learning_rate=learning_rate\n",
        "    )\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices):\n",
        "    print(f'physical devices found: {physical_devices}')\n",
        "    mem_growth = tf.config.experimental.get_memory_growth(physical_devices[0])\n",
        "    print(f'memory growth of dev0: {mem_growth}')\n",
        "    if not mem_growth:\n",
        "        try:\n",
        "            tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "            print(f'memory growth of dev0: {tf.config.experimental.get_memory_growth(physical_devices[0])} (now enabled)')\n",
        "        except:\n",
        "            print(f'failed to modify device (likely already initialised)')\n",
        "else:\n",
        "    print('physical device not found')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "physical devices found: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\nmemory growth of dev0: True\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1715549595949
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from numpy files, then train and evaluate of whichever model, by default the baseline CRT-Net\n",
        "\n",
        "The loss function depends on whether doing multilabel or single label classification, which is inferred from the data (ie if each sample has exlusive one hot encoding or multiple)\n",
        "\n",
        "The class names are read to label the outputs more clearly based on SNOMED, vs just having unlabeled one-hot encoding position"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the original/alternate architecture:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import numpy as np\n",
        "    \n",
        "stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=0.00001)\n",
        "\n",
        "# load the data from the file\n",
        "samples = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_multilabel_samples.npy'))\n",
        "one_hot_encoding_labels = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_multilabel_one_hot_encoding_labels.npy'))\n",
        "classes = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_multilabel_classes.npy'))\n",
        "\n",
        "is_multilabel = any(sum(row) > 1 for row in one_hot_encoding_labels)\n",
        "\n",
        "use_alternate = True # if True: leaky ReLU (alpha=0.3); dropout (rate=0.2); max pos encoding = 2048; SeLU activation on pre-output\n",
        "initial_learning_rate = 0.0001\n",
        "\n",
        "create_crtnet_method = create_crtnet_rwkv# create_crtnet_alternate if use_alternate else create_crtnet_original\n",
        "model = create_crtnet_method(\n",
        "    number_of_leads=samples.shape[2],\n",
        "    num_classes=one_hot_encoding_labels.shape[1],\n",
        "    multilabel=is_multilabel,\n",
        "    learning_rate=initial_learning_rate)\n",
        "# model already compiled. it can still be recompiled if needed\n",
        "\n",
        "model.summary()\n",
        "\n",
        "train_and_evaluate_model(\n",
        "    model,\n",
        "    samples=samples,\n",
        "    one_hot_encoding_labels=one_hot_encoding_labels,\n",
        "    callbacks=[reduce_lr, stopping],\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    classes=classes,\n",
        "    multilabel=is_multilabel,\n",
        "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\", \"g-\", \"g-*\"] # has f1 score so add green line for this\n",
        ")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-05-12 21:33:43.564104: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.564149: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.564186: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.565234: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.565340: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.565591: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.565805: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.565828: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.565854: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.566188: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.566760: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.566943: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.566960: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.567405: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.576418: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.577676: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.894020: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.894089: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.894598: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.895044: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.895608: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.895652: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.895686: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.896115: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.896181: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.896376: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.896973: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.897005: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.897505: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.897616: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.898183: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.898515: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:33:43.898791: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:33:43.899651: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.231140: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.231243: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.232238: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.232293: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.232487: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.232785: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.232808: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.233866: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.233884: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.233989: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.234683: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.235203: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.235241: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n\n2024-05-12 21:40:18.235888: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.236589: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n2024-05-12 21:40:18.236615: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, None, 12)]        0         \n                                                                 \n vgg_net (VGGNet)            (None, None, 128)         2414976   \n                                                                 \n bi_gru (BiGRU)              (None, None, 256)         198144    \n                                                                 \n stacked_rwkv (StackedRWKV)  (None, None, 256)         13677568  \n                                                                 \n global_average_pooling1d (  (None, 256)               0         \n GlobalAveragePooling1D)                                         \n                                                                 \n dense (Dense)               (None, 18)                4626      \n                                                                 \n dense_1 (Dense)             (None, 9)                 171       \n                                                                 \n=================================================================\nTotal params: 16295485 (62.16 MB)\nTrainable params: 16295485 (62.16 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/30\n97/97 [==============================] - 141s 360ms/step - loss: 0.1135 - accuracy: 0.2141 - val_loss: 0.0796 - val_accuracy: 0.3503 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0772 - accuracy: 0.3626 - val_loss: 0.0735 - val_accuracy: 0.4419 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/30\n97/97 [==============================] - 20s 206ms/step - loss: 0.0722 - accuracy: 0.4262 - val_loss: 0.0716 - val_accuracy: 0.4869 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0673 - accuracy: 0.4936 - val_loss: 0.0664 - val_accuracy: 0.5174 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0620 - accuracy: 0.5518 - val_loss: 0.0589 - val_accuracy: 0.5828 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0593 - accuracy: 0.5794 - val_loss: 0.0615 - val_accuracy: 0.5596 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0560 - accuracy: 0.6058 - val_loss: 0.0573 - val_accuracy: 0.6163 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0536 - accuracy: 0.6274 - val_loss: 0.0545 - val_accuracy: 0.6366 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0511 - accuracy: 0.6463 - val_loss: 0.0551 - val_accuracy: 0.6308 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0492 - accuracy: 0.6657 - val_loss: 0.0505 - val_accuracy: 0.6788 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/30\n97/97 [==============================] - 20s 206ms/step - loss: 0.0473 - accuracy: 0.6872 - val_loss: 0.0495 - val_accuracy: 0.6831 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0452 - accuracy: 0.7045 - val_loss: 0.0512 - val_accuracy: 0.6933 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0429 - accuracy: 0.7158 - val_loss: 0.0500 - val_accuracy: 0.6875 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0417 - accuracy: 0.7281 - val_loss: 0.0448 - val_accuracy: 0.7151 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0405 - accuracy: 0.7357 - val_loss: 0.0473 - val_accuracy: 0.7093 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0388 - accuracy: 0.7442 - val_loss: 0.0483 - val_accuracy: 0.7078 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0387 - accuracy: 0.7420 - val_loss: 0.0448 - val_accuracy: 0.7224 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0376 - accuracy: 0.7402 - val_loss: 0.0461 - val_accuracy: 0.7253 - lr: 1.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0346 - accuracy: 0.7659 - val_loss: 0.0425 - val_accuracy: 0.7456 - lr: 5.0000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0327 - accuracy: 0.7817 - val_loss: 0.0441 - val_accuracy: 0.7384 - lr: 5.0000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0322 - accuracy: 0.7849 - val_loss: 0.0436 - val_accuracy: 0.7297 - lr: 5.0000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0317 - accuracy: 0.7867 - val_loss: 0.0443 - val_accuracy: 0.7398 - lr: 5.0000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0306 - accuracy: 0.7908 - val_loss: 0.0445 - val_accuracy: 0.7297 - lr: 5.0000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0288 - accuracy: 0.7993 - val_loss: 0.0446 - val_accuracy: 0.7297 - lr: 2.5000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0286 - accuracy: 0.7992 - val_loss: 0.0450 - val_accuracy: 0.7311 - lr: 2.5000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0274 - accuracy: 0.8056 - val_loss: 0.0459 - val_accuracy: 0.7369 - lr: 2.5000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0271 - accuracy: 0.8076 - val_loss: 0.0463 - val_accuracy: 0.7180 - lr: 2.5000e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/30\n97/97 [==============================] - 20s 204ms/step - loss: 0.0259 - accuracy: 0.8166 - val_loss: 0.0468 - val_accuracy: 0.7384 - lr: 1.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/30\n97/97 [==============================] - 20s 205ms/step - loss: 0.0253 - accuracy: 0.8215 - val_loss: 0.0464 - val_accuracy: 0.7369 - lr: 1.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x500 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "22/22 [==============================] - 16s 61ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nOverall Accuracy: 69.19%\n              precision    recall  f1-score   support\n\n         PVC       0.86      0.45      0.59        69\n          AF       0.85      0.95      0.89       128\n        LBBB       0.81      0.85      0.83        20\n         STE       0.68      0.41      0.51        32\n        IAVB       0.87      0.83      0.85        75\n         PAC       0.67      0.04      0.07        55\n           N       0.71      0.76      0.74        97\n         STD       0.73      0.64      0.68        80\n        RBBB       0.87      0.96      0.91       181\n\n   micro avg       0.82      0.74      0.78       737\n   macro avg       0.78      0.65      0.67       737\nweighted avg       0.80      0.74      0.74       737\n samples avg       0.75      0.75      0.74       737\n\nAccuracy (PVC): 93.75%\nAccuracy (AF): 95.78%\nAccuracy (LBBB): 98.98%\nAccuracy (STE): 96.37%\nAccuracy (IAVB): 96.80%\nAccuracy (PAC): 92.15%\nAccuracy (N): 92.30%\nAccuracy (STD): 93.02%\nAccuracy (RBBB): 95.20%\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1715550760836
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# get stats of the data\n",
        "samples = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_singlelabel_samples.npy'))\n",
        "one_hot_encoding_labels = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_singlelabel_one_hot_encoding_labels.npy'))\n",
        "classes = np.load(os.path.join(\"data\", 'cpsc_2018_crtnet_singlelabel_classes.npy'))\n",
        "\n",
        "print(f\"Number of samples: {samples.shape[0]}\")\n",
        "print(f\"Number of leads: {samples.shape[2]}\")\n",
        "print(f\"Number of classes: {one_hot_encoding_labels.shape[1]}\")\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# get counts of each class\n",
        "class_counts = np.sum(one_hot_encoding_labels, axis=0)\n",
        "class_counts = dict(zip(classes, class_counts))\n",
        "print(f\"Class counts: {class_counts}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of samples: 6877\nNumber of leads: 12\nNumber of classes: 19\nClasses: ['PVC' 'AF' 'LBBB' 'STE' 'IAVB' 'PAC' 'N' 'STD' 'RBBB']\nClass counts: {'PVC': 0.0, 'AF': 1081.0, 'LBBB': 342.0, 'STE': 605.0, 'IAVB': 96.0, 'PAC': 107.0, 'N': 655.0, 'STD': 362.0, 'RBBB': 295.0}\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715558146058
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "tf215gpu"
    },
    "kernelspec": {
      "name": "tf215gpu",
      "language": "python",
      "display_name": "tf215gpu"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
