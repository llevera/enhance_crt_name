{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715635735602
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import wfdb\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import random\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "label_group_map = {'N':'N', 'L':'N', 'R':'N', 'e':'N', 'j':'N', 'A':'S', 'a':'S', 'J':'S', 'S':'S', 'V':'V', '!':'V','E':'V','[':'V',']':'V', 'f':'Q', '/':'Q', 'Q':'Q', 'F':'F'  }\n",
        "\n",
        "def resample_unequal(ts, fs_in, fs_out):\n",
        "    \"\"\"\n",
        "    interploration\n",
        "    \"\"\"\n",
        "    fs_in, fs_out = int(fs_in), int(fs_out)\n",
        "    if fs_out == fs_in:\n",
        "        return ts\n",
        "    else:\n",
        "        x_old = np.linspace(0, 1, num=fs_in, endpoint=True)\n",
        "        x_new = np.linspace(0, 1, num=fs_out, endpoint=True)\n",
        "        y_old = ts\n",
        "        f = interp1d(x_old, y_old, kind='linear')\n",
        "        y_new = f(x_new)\n",
        "        return y_new\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    path = 'mit-bih-arrhythmia-database-1.0.0'\n",
        "    save_path = 'data/'\n",
        "#    valid_lead = ['MLII', 'II', 'I', 'MLI', 'V5']\n",
        "    valid_lead = ['MLII'] \n",
        "    fs_out = 360\n",
        "\n",
        "    all_data = []\n",
        "    all_group = []\n",
        "\n",
        "    with open(os.path.join(path, 'RECORDS'), 'r') as fin:\n",
        "        all_record_name = fin.read().strip().split('\\n')\n",
        "\n",
        "    for record_name in all_record_name:\n",
        "        try:\n",
        "            tmp_ann_res = wfdb.rdann(path + '/' + record_name, 'atr').__dict__\n",
        "            tmp_data_res = wfdb.rdsamp(path + '/' + record_name)\n",
        "        except:\n",
        "            print('read data failed')\n",
        "            continue\n",
        "        fs = tmp_data_res[1]['fs']\n",
        "\n",
        "        ## total 1 second for each\n",
        "        left_offset = int(1.0*fs / 2)\n",
        "        right_offset = int(fs) - int(1.0*fs / 2)\n",
        "\n",
        "        lead_in_data = tmp_data_res[1]['sig_name']\n",
        "        my_lead_all = []\n",
        "        for tmp_lead in valid_lead:\n",
        "            if tmp_lead in lead_in_data:\n",
        "                my_lead_all.append(tmp_lead)\n",
        "        if len(my_lead_all) != 0:\n",
        "            for my_lead in my_lead_all:\n",
        "                channel = lead_in_data.index(my_lead)\n",
        "                tmp_data = tmp_data_res[0][:, channel]\n",
        "\n",
        "                idx_list = list(tmp_ann_res['sample'])\n",
        "                label_list = tmp_ann_res['symbol']\n",
        "                for i in range(len(label_list)):\n",
        "                    s = label_list[i]\n",
        "                    if s in label_group_map.keys():\n",
        "                        idx_start = idx_list[i]-left_offset\n",
        "                        idx_end = idx_list[i]+right_offset\n",
        "                        if idx_start < 0 or idx_end > len(tmp_data):\n",
        "                            continue\n",
        "                        else:\n",
        "                            all_data.append(resample_unequal(tmp_data[idx_start:idx_end], fs, fs_out))\n",
        "                            all_group.append(label_group_map[s])\n",
        "                    else:\n",
        "                        continue\n",
        "                print('record_name:{}, lead:{}, fs:{}'.format(record_name, my_lead, fs))\n",
        "        else:\n",
        "            print('lead in data: [{0}]. no valid lead in {1}'.format(lead_in_data, record_name))\n",
        "            continue\n",
        "\n",
        "    all_data = np.array(all_data)\n",
        "    all_group = np.array(all_group)\n",
        "    print(all_data.shape)\n",
        "    print(Counter(all_group))\n",
        "    np.save(os.path.join(save_path, 'mitdb_data.npy'), all_data)\n",
        "    np.save(os.path.join(save_path, 'mitdb_group.npy'), all_group)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715637359271
        }
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import utils\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import numpy as np\n",
        "from src import train_and_evaluate\n",
        "from importlib import reload\n",
        "reload(train_and_evaluate)\n",
        "from src import crtnet_models\n",
        "reload(crtnet_models)\n",
        "\n",
        "def label2index(i):\n",
        "    m = {'N':0, 'S':1, 'V':2, 'F':3, 'Q':4}\n",
        "    return m[i]\n",
        "\n",
        "def load_and_preprocess_data(path, num_classes):\n",
        "    data = np.load(os.path.join(path, 'mitdb_data.npy'))\n",
        "    label_str = np.load(os.path.join(path, 'mitdb_group.npy'))\n",
        "    label = np.array([label2index(i) for i in label_str])\n",
        "    one_hot = utils.to_categorical(label, num_classes=num_classes)\n",
        "    return data, one_hot\n",
        "\n",
        "path = 'data/'\n",
        "num_classes = 5\n",
        "class_names = ['N', 'S', 'V', 'F', 'Q']  # Update based on your classes\n",
        "\n",
        "samples, one_hot_encoding_labels = load_and_preprocess_data(path, num_classes)\n",
        "\n",
        "stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=0.00001)\n",
        "\n",
        "create_crtnet_method = crtnet_models.create_crtnet_alternate_vgg1\n",
        "\n",
        "train_and_evaluate.train_and_evaluate_model(\n",
        "    create_crtnet_method,\n",
        "    samples=samples,\n",
        "    one_hot_encoding_labels=one_hot_encoding_labels,\n",
        "    callbacks=[reduce_lr, stopping],\n",
        "    is_multilabel=False,\n",
        "    epochs=25,\n",
        "    folds=None,\n",
        "    batch_size=128,\n",
        "    classes=class_names,\n",
        "    initial_learning_rate=0.001, #\n",
        "    number_of_leads=1\n",
        ")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "tf215gpu"
    },
    "kernelspec": {
      "display_name": "tf215gpu",
      "language": "python",
      "name": "tf215gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
